# ğŸ“˜ Ã‰tape 4 â€“ Scripts SQL pour la base de donnÃ©es PostgreSQL

Ce dossier contient les scripts SQL utilisÃ©s pour :

- CrÃ©er la base de donnÃ©es et les tables relationnelles Ã  partir des fichiers bruts (`sirh`, `evaluations_annuelles`, `sondage_bien_etre`)
- Fusionner les donnÃ©es et reproduire les transformations du pipeline Python en SQL
- Exporter un dataset final compatible avec le modÃ¨le `pipeline.joblib`
- GÃ©rer la traÃ§abilitÃ© des prÃ©dictions (inputs/outputs enregistrÃ©s en base)

---

## ğŸ“ Contenu des scripts

| Fichier                          | RÃ´le                                                               |
|----------------------------------|--------------------------------------------------------------------|
| `01_create_tables.sql`           | CrÃ©e les tables `sirh`, `evaluations_annuelles`, `sondage_bien_etre` |
| `02_insert_data.sql`             | InsÃ¨re les donnÃ©es brutes (via `COPY`, `INSERT` ou ORM)           |
| `03_joins_fusion.sql`            | Joint les 3 tables pour produire une table fusionnÃ©e de travail   |
| `04_feature_engineering.sql`     | Applique les transformations (encodages, ratios, dÃ©rivÃ©es, etc.)  |
| `05_export_final.sql`            | GÃ©nÃ¨re la table finale `dataset_pipeline_final` et/ou exporte en CSV |
| `06_register_inputs_outputs.sql` | CrÃ©e les tables dâ€™enregistrement des inputs et outputs du modÃ¨le  |

---

## ğŸ§ª ExÃ©cution recommandÃ©e

Ces scripts doivent Ãªtre exÃ©cutÃ©s **dans l'ordre indiquÃ© ci-dessus**, soit :

- Via pgAdmin (interface SQL)
- Via `psql` (en ligne de commande)
- Ou traduits en Python avec SQLAlchemy (`app/db/...`)

---

## ğŸ“¦ Connexion PostgreSQL

Assurez-vous que PostgreSQL est bien installÃ© en local.

**ParamÃ¨tres par dÃ©faut** recommandÃ©s pour `.env` ou `config.py` :

```env
DB_NAME=p5_classification
DB_USER=postgres
DB_PASSWORD=postgres
DB_HOST=localhost
DB_PORT=5432

```

> ğŸ” Pour la documentation dÃ©taillÃ©e du schÃ©ma relationnel, voir docs/sql/schema_base_donnees.md.
